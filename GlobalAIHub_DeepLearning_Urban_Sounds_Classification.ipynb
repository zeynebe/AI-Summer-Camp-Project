{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPNy0PAUP2hE1kR7oDxAifU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zeynebe/AI-Summer-Camp-Project/blob/main/GlobalAIHub_DeepLearning_Urban_Sounds_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VERİ SETİ ÖNİŞLEME, \n",
        "LABELLING \n",
        "VE \n",
        "test kümelerine ayrıştırıp kaydetme\n",
        "\n"
      ],
      "metadata": {
        "id": "UQEP8RZ1SbJY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "TtyARHJuRUDW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Working with directory library\n",
        "import os\n",
        "from os import path, listdir\n",
        "from os.path import isdir\n",
        "\n",
        "# We'll import the cv2(computer vision 2) and PIL (Python Imaging Library) libraries \n",
        "# to open, work and process our images\n",
        "import cv2 as cv    \n",
        "import PIL\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import librosa\n",
        "\n",
        "\n",
        "# image data preprocessing\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "\n",
        "# Pathlib module ensures that your file paths work the same in different operating systems\n",
        "import pathlib\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D,Dense,Dropout, Flatten,Activation, BatchNormalization,MaxPooling2D\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "# Image visualization\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYBPbTrfe1h7",
        "outputId": "1d459c16-0f6c-420c-cc2c-6c4a299558a2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_dataset = \"/content/gdrive/MyDrive/spectrograms\""
      ],
      "metadata": {
        "id": "tb5wcOUXjdGJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]"
      ],
      "metadata": {
        "id": "OHlxkM7grclE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(x):\n",
        "  x = (x-x.min())/(x.max()-x.min())\n",
        "  return x"
      ],
      "metadata": {
        "id": "8HLWeUlq2ljz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = []\n",
        "errors_file = open(\"errors.txt\", \"a\")\n",
        "number = 0\n",
        "error = 0\n",
        "\n",
        "\n",
        "for category in categories:\n",
        "  idx = categories.index(category)\n",
        "  img_per_category = 0\n",
        "  for image in os.listdir(f\"{path_to_dataset}/{category}\"):\n",
        "    if img_per_category == 1000:\n",
        "        break\n",
        "    path_to_image = f\"{path_to_dataset}/{category}/{image}\"\n",
        "\n",
        "    try:\n",
        "        img = cv.imread(path_to_image, cv.IMREAD_GRAYSCALE)\n",
        "        img = cv.resize(img, (128, 128))\n",
        "        img = normalize(img)\n",
        "        images.append([img, idx])\n",
        "        \n",
        "    except Exception as e:\n",
        "        error += 1\n",
        "        errors_file.write(f\"{error} | {e}\\n\")\n",
        "    finally:\n",
        "        number += 1\n",
        "    \n",
        "    print(f\"\\rProcessed: {number} | Errors: {error}\", end=\"\")\n",
        "\n",
        "errors_file.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rz6xXAC7vbvT",
        "outputId": "e2e61175-1309-414f-956f-6dd499a9e4f3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed: 8732 | Errors: 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDT36k3A7XJD",
        "outputId": "2143cb5f-5435-4ee2-c0c3-eb81851968d3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8732"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "FmgqB7xw8HfW"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(images)"
      ],
      "metadata": {
        "id": "_vkakrjk8OHK"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(images)[:,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8N57N1qh72i9",
        "outputId": "fb562c95-de30-44a8-9f14-bcf5133204a6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 1, 6, ..., 9, 0, 0], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for image, idx in images:\n",
        "  X.append(image)\n",
        "  y.append(idx)"
      ],
      "metadata": {
        "id": "5IflJXFqjcLU"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X)"
      ],
      "metadata": {
        "id": "J_t3BNeujbyv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f632591b-27e8-4cb7-ec8b-816e834d8da4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8732"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeaPHbSd8-Sh",
        "outputId": "bf7954dd-3186-4ae3-f980-91c54f9e050b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8732"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "X_val =[]\n",
        "y_val = []\n",
        "\n",
        "X_test=[]\n",
        "y_test=[]"
      ],
      "metadata": {
        "id": "1VTt1L8K8-LL"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=2)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=2)\n",
        "print(len(X_train),len(y_train))\n",
        "print(len(X_test),len(y_test))\n",
        "print(len(X_val),len(y_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORKAvlHm9fzI",
        "outputId": "aed79da0-d2f1-4c7a-da7d-3c43d5257535"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5588 5588\n",
            "1747 1747\n",
            "1397 1397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "rA5FTU7x9fs5"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"X_train.pickle\", \"wb\") as f:\n",
        "  pickle.dump(X_train, f)\n",
        "with open(\"y_train.pickle\", \"wb\") as f:\n",
        "  pickle.dump(y_train, f)\n",
        "\n",
        "with open(\"X_val.pickle\", \"wb\") as f:\n",
        "  pickle.dump(X_val, f)\n",
        "with open(\"y_val.pickle\", \"wb\") as f:\n",
        "  pickle.dump(y_val, f)\n",
        "\n",
        "with open(\"X_test.pickle\", \"wb\") as f:\n",
        "  pickle.dump(X_test, f)\n",
        "with open(\"y_test.pickle\", \"wb\") as f:\n",
        "  pickle.dump(y_test, f)"
      ],
      "metadata": {
        "id": "acxlDT2X9fof"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Hazırlanması ve Eğitimi "
      ],
      "metadata": {
        "id": "HLxrDxBQB2B-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
        "    include_top=False,\n",
        "    weights = \"imagenet\",\n",
        "    input_shape = (128, 128, 3),\n",
        "    pooling = \"max\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pogTvxNy8-Fk",
        "outputId": "66dff84a-73e9-4e4d-ec9f-c16badc0cb7b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_128_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "9420800/9406464 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "OE6g22CGDpRO"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.keras.layers.Flatten()(base_model.output)\n",
        "x = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "\n",
        "predictions = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)"
      ],
      "metadata": {
        "id": "M29Rx1EcDxGP"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "head_model = tf.keras.Model(inputs=base_model.inputs, outputs=predictions)"
      ],
      "metadata": {
        "id": "iF8rUGWUDpLN"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "head_model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "gxXLd5z5DpC1"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = head_model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=128,\n",
        "    epochs=10,\n",
        "    validation_data=(X_val, y_val)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "iUVZD3l-GzsM",
        "outputId": "0cb51d99-edd6-4a1c-afc3-540d8f807a5b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-c0e1e32d7b61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m         \"input: {}, {}\".format(\n\u001b[0;32m--> 987\u001b[0;31m             _type_name(x), _type_name(y)))\n\u001b[0m\u001b[1;32m    988\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m     raise RuntimeError(\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'numpy.ndarray'>\"}), (<class 'list'> containing values of types {\"<class 'int'>\"})"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_WIDTH=128\n",
        "IMAGE_HEIGHT=128\n",
        "IMAGE_CHANNELS=3\n",
        "\n",
        "model = Sequential([\n",
        "\n",
        "Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)),\n",
        "BatchNormalization(),\n",
        "MaxPooling2D(pool_size=(2, 2)),\n",
        "Dropout(0.25),\n",
        "\n",
        "Conv2D(64, (3, 3), activation='relu'),\n",
        "BatchNormalization(),\n",
        "MaxPooling2D(pool_size=(2, 2)),\n",
        "Dropout(0.25),\n",
        "\n",
        "Conv2D(128, (3, 3), activation='relu'),\n",
        "BatchNormalization(),\n",
        "MaxPooling2D(pool_size=(2, 2)),\n",
        "Dropout(0.25),\n",
        "\n",
        "Flatten(),\n",
        "Dense(512, activation='relu'),\n",
        "BatchNormalization(),\n",
        "Dropout(0.5),\n",
        "Dense(1, activation='sigmoid'), # 2 because we have cat and dog classes\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oE1g2vGeH7qz",
        "outputId": "8776e8fe-8f99-459e-f51d-682aedbe8e49"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 126, 126, 32)      896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 126, 126, 32)     128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 63, 63, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 63, 63, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 61, 61, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 61, 61, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 30, 30, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 30, 30, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 28, 28, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 28, 28, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 14, 14, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 512)               12845568  \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,942,273\n",
            "Trainable params: 12,940,801\n",
            "Non-trainable params: 1,472\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}